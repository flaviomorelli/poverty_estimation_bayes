\section{Evaluation of Bayesian models}

There are numerous ways to evaluate Bayesian models.
(PIIRONEN VEHTARI 2017) provides an overview of evaluation methods that quantify predictive power of a model, which can be used to compare different models.
On the other hand, Bayesian inference provides two additional checking tools: prior and posterior predictive checks.
The main idea here is to generate numerous samples either from the prior predictive or posterior predictive distribution described in section XY.
Thus, it is possible to check how the model behaves before and after fitting the data and whether the generated samples are in a plausible range of the dependent variable.
This section focuses on PSIS-LOO as a measure of predictive power and includes a brief discussion of prior and posterior predictive checks.

Given some data $y$ and future observations $\tilde y_i, i = 1, ..., N$, where $N$ is the original sample size, the quality of the predictive distribution can be defined in terms of a utility function in terms of the logarithmic score (Good, 1952, Piironen/Vehtari 2017)
\begin{gather*}
    u(\tilde y_i) = \displaystyle \sum_{i = 1}^N\log p(\tilde y_i|y).
\end{gather*}
However, as $\tilde y$ is unobserved, it is necessary to marginalize it out of $u$, thus getting the expected utility
\begin{gather*}
    \text{elpd} =
    \displaystyle \sum_{i = 1}^N E[\log p(\tilde y_i| y)] =
    \displaystyle \sum_{i = 1}^N \int p_t(\tilde y_i) \log p(\tilde y_i| y) d \tilde y_i,
\end{gather*}
where $p_t$ is the true data generating distribution and elpd stands for expected log pointwise predictive density for a new data set.
As $p_t$ is unknown, it is not possible to calculate the elpd directly.
An unbiased estimate for the elpd is given by
\begin{gather}
    \text{elpd}_{\text{loo}} =
    \displaystyle \sum_{i = 1}^N \log p(\tilde y_i| y_{-i}),
    ~~~ p(\tilde y_i| y_{-i}) = \displaystyle \int p(y_i | \theta)p(\theta|y_{-i})d\theta.
\end{gather}
Here, $p(\tilde y_i| y_{-i})$ is the leave-one-out predictive distribution given $y_{-i}$, i.e. the data without the $i$-th observation.
In practice, $\text{elpd}_{\text{loo}}$ is estimated efficiently by Pareto-smoothed importance sampling without having to refit the model $N$ times and is therefore referred to as PSIS-LOO.
A higher PSIS-LOO indicates a model with a higher predictive power.
Pareto smoothing is not only useful for the efficient estimation of elpd$_{\text{loo}}$, but it also provides a diagnostic to whether the estimated PSIS-LOO can be trusted.
Specifically if the shape parameter $k$ of the Pareto distribution is higher than 0.7, then PSIS-LOO is not reliable(Vehtari/Gelman 2017).
This might be alleviate with the moment match method (BÃ¼rkner, Vehtari), but it can also indicate that the model does not deal with outliers well.
Note that a utility function that quantifies predictive power takes into account the distributional characteristics of the model.
In contrast, loss function approaches such as the root mean squared error (RMSE) or the mean absolute error (MAE) measure the distance between the predicted values and the true values, but are distribution-agnostic.

Beyond PSIS-LOO, prior and posterior predictive checks are useful to asses model quality.
The main idea is to generate multiple sample from the prior predictive distribution $\int p(\theta) p(y|\theta)d\theta$ or from the posterior predictive distribution $\int p(y | \theta) p(\theta|y) d\theta$.
With the sample it is possible to compute new statistics.

