\chapter{Appendix: An Introduction to Bayesian Computation}

\label{ch:computation}

A central challenge in Bayesian statistics is model estimation.
The integral of the marginal likelihood $p(y) = \int p(\theta)p(y|\theta)d\theta$ is usually intractable.
Analytical solutions exist only for a limited group of models where prior and likelihood are conjugate distributions.
A thorough review of Bayesian computation methods is beyond the scope of this paper.
This section provides a short overview of algortihms and concepts relevant to this paper.
The focus is on Markov Chain Monte Carlo (MCMC) and variational inference, but there are other alternatives such as Laplace Approximations \citep{gomez-rubio_bayesian_2020}.

As the normalizing term $p(y)$ in Bayes' theorem is intractable, the posterior distribution has to be approximated.
Simple Monte Carlo algorithms such as rejection or importance sampling are effective only for low dimensional parameter spaces.
Monte Carlo Markov Chain (MCMC) is a widely used family of algorithms which builds upon the concepts of Monte Carlo approximations.
The following overview on MCMC is largely based on \cite{gelman_bayesian_2014} Chapters 10 to 12.
The main idea of MCMC is to have a Markov Chain, which moves through the parameter space according to some previously defined transition distribution.
Each step of the Markov Chain is a proposed sample to approximate the \textit{target} distribution – i.e. the distribution which has to be approximated.
A proposal can be accepted or rejected according to a pre-defined rule, which is based on the acceptance ratio $r$ of the target probability at the current step and the target probability at the last step.
Because of the ratio, any normalizing constant (the marginal likelihood) cancels out, which allows to find an approximation to the target distribution using only the unnormalized target distribution.
Generally speaking, a proposal from the Markov chain that increases the probability of the unnormalized target distribution is always accepted.
Otherwise, $r$ is smaller than 1 and the proposal is accepted with probability $r$.
Under certain conditons, the Markov chain is guaranteed to converge to a stationary distribution as the number of steps goes to infinity \citep[Chapter 11]{gelman_bayesian_2014}.
As any computation has only a finite number of steps in the real world, it is necessary to check whether the accepted proposals from the Markov chain are reliable.
A common approach is to start multiple Markov chains (usually between two and four) with different initial values at random.
After discarding the warm-up iterations needed to get from the initial value to the stationary distribution, it is possible to check whether the chains have mixed well – i.e., converged to a similar distribution.
While it is sometimes possible to recognize mixing problems with the Markov chains traceplots, it is better to use a numeric diagnostic such as $\hat R$ \citep{vehtari_rank-normalization_2021}.
An $\hat R$ higher than 1.01 indicates either that there is a trend in any given chain so that it cannot be stationary or that the chains have converged to different values.

The Metropolis-Hastings algorithm (with its special case, the Gibbs sampler) falls under the MCMC category and is characterized by exploring the parameter space through a random walk.
However, there are two problems with this approach.
Firstly, the Markov chain can get stuck in certain regions of the parameter space while exploring posteriors where the parameters are highly correlated.
Secondly, the sparsity induced in a parameter space with increasing dimensionality makes the random walk approach very inefficient.
Hamiltonian Monte Carlo (HMC) is an MCMC algorithm that can explore high dimensional spaces much more efficiently than the Metropolis-Hastings algorithm.
The main idea behind HMC is to add a momentum parameter for each one of the model parameters and use Hamiltonian dynamics to explore the parameter space and find a proposal.
HMC is a mix of random and deterministic elements.
While the momentum parameters are sampled at random, the parameter space exploration which ultimately leads to a proposal is based entirely on a deterministic set of Hamiltonian differential equations.
The use of differential equations is an unexpected advantage of HMC, because their discretization with symplectic integrater offers a diagnostic unique to HMC: \textit{divergences}.
A divergence occurs when there is a region of high curvature in the parameter-momentum space, which pushes the symplectic integrator towards the edges of such a space.
While the exact explanation is somewhat technical, a divergence indicates that there might be areas in the parameter space from which the sampler cannot explore well enough.
This is a sign that the resulting Monte Carlo approximation is not reliable, because of model misspecification or because there is a better parametrization for the model \citep{betancourt_conceptual_2017, neal_mcmc_2011}.
A more efficient version of the HMC algorithm is NUTS \citep{hoffman_no-u-turn_2014}, which has a more complex heuristic for the deterministic exploration.
This is the most commonly used MCMC algorithm in Bayesian frameworks such as \code{Stan}.

Variational inference is an alternative approximation method, which aims to find a distribution that minimizes the divergence (usually Kullback-Leibler) to the target distribution.
While variational inference is very fast compared to MCMC, it lacks its theoretical guarantees.
Therefore, the resulting variational approximation might be highly misleading \citep{blei_variational_2017}.
However, variational inference is a useful tool to do a first check of the model.
Because it is faster, it also makes it possible to recognize potential problems sooner.
Moreover, there are some types of models which would take a very long time to estimate using MCMC, e.g., topic models \citep{blei_latent_2003}.

%This short overview of MCMC and variational inference provides the necessary elements to understand some problems that arise when fitting Bayesian models.
%The next step is to discuss about how to evaluate the predictive quality of Bayesian models before combining all building blocks into a workflow.

